{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model6(Personality_Prediction)_Notebook5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "750bbe8ea77449429e2e49c9b63f5892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e4e89f6f1fa4eaf8b4da68802310bee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_492c70e0281f4e9c9da08e79da0db614",
              "IPY_MODEL_c5efa36eeb7443e6843640830e4bf361",
              "IPY_MODEL_684900bc86a74fabbbd66e4825c17512"
            ]
          }
        },
        "8e4e89f6f1fa4eaf8b4da68802310bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "492c70e0281f4e9c9da08e79da0db614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f0fab9813d7401b8e03098581cf3c54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8adafecee1e49b8b280c17567a584b6"
          }
        },
        "c5efa36eeb7443e6843640830e4bf361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35f07f1bdb28476e8917d80d6b42a7de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c013a5b7c634f08b032decb064739e1"
          }
        },
        "684900bc86a74fabbbd66e4825c17512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99a8ee20ea124cbcb5c0129588d84dc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 14.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b25ab2bedf174cadad423b5eb404209d"
          }
        },
        "0f0fab9813d7401b8e03098581cf3c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8adafecee1e49b8b280c17567a584b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35f07f1bdb28476e8917d80d6b42a7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c013a5b7c634f08b032decb064739e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99a8ee20ea124cbcb5c0129588d84dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b25ab2bedf174cadad423b5eb404209d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c8ae835d3b3439da47b6ab6e9bc3e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4a6d3341f354090a346a7c38039bcf1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_837652cd45934caf83bfad4d8c2226d3",
              "IPY_MODEL_0bc795d4dca04b1c8b43f66e5386a4d7",
              "IPY_MODEL_1e292d88fbf84621ab9b515c00437d5a"
            ]
          }
        },
        "c4a6d3341f354090a346a7c38039bcf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "837652cd45934caf83bfad4d8c2226d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b54970944f66436b81e51a42bdf37be1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a2bc33148c5417e8a1a33a192ff6586"
          }
        },
        "0bc795d4dca04b1c8b43f66e5386a4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_649b2c5f22e7445f9c3a9fc78f8e0dc5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bde5e24c8bc44fca8f1148329055cdd"
          }
        },
        "1e292d88fbf84621ab9b515c00437d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b51ae64795ac4cad939a9b30f606227c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:12&lt;00:00, 34.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46ae8ea705db4881ba8c5ec56ffe08d1"
          }
        },
        "b54970944f66436b81e51a42bdf37be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a2bc33148c5417e8a1a33a192ff6586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "649b2c5f22e7445f9c3a9fc78f8e0dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bde5e24c8bc44fca8f1148329055cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b51ae64795ac4cad939a9b30f606227c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46ae8ea705db4881ba8c5ec56ffe08d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b30d62adc659440f8e4b418d263110df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bed698ab83194b9f9aa5d1979090882a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a123d45a2688436a83f6bc9970cdbf82",
              "IPY_MODEL_5cd2c095c5c9469684268c034300b882",
              "IPY_MODEL_31ec75b8d1414cda88fd4081e5e2ce6f"
            ]
          }
        },
        "bed698ab83194b9f9aa5d1979090882a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a123d45a2688436a83f6bc9970cdbf82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4beef35a7db24bd9ab7b31a7c5c4d556",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_811473abfd1247709101f7c7691f7de7"
          }
        },
        "5cd2c095c5c9469684268c034300b882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af7ff4d504044cb4a9fd91008b06a8e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c09e2edebd224499a121a59f589adc7a"
          }
        },
        "31ec75b8d1414cda88fd4081e5e2ce6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0c314bbef8d4f76b38584fd291ee265",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 190kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7f3c45bda7d4c6f9b4ab97a98965dee"
          }
        },
        "4beef35a7db24bd9ab7b31a7c5c4d556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "811473abfd1247709101f7c7691f7de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af7ff4d504044cb4a9fd91008b06a8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c09e2edebd224499a121a59f589adc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0c314bbef8d4f76b38584fd291ee265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7f3c45bda7d4c6f9b4ab97a98965dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99c42d0c77644c24bc9a7d956d5ed768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03b88df1da0f4766afb9bd6c09b03eb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f666bfb3a094f398233e2784020bc28",
              "IPY_MODEL_efe654c96a314f458bbc5e78bb94d057",
              "IPY_MODEL_6f0f9847e75f4d3c9b19fffeb28c1809"
            ]
          }
        },
        "03b88df1da0f4766afb9bd6c09b03eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f666bfb3a094f398233e2784020bc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce7a742531c245bfa10f4e4f734048e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d395fdd31cf493dbcd3f4f7026b1cb0"
          }
        },
        "efe654c96a314f458bbc5e78bb94d057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4f0ec8526b04e89827253b97ffcb72e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8689087c1a244680bc9d8152efba780f"
          }
        },
        "6f0f9847e75f4d3c9b19fffeb28c1809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_731be2c045644958a2c68beb31dc1917",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 713B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd504e178f4142549eeefee533e96b64"
          }
        },
        "ce7a742531c245bfa10f4e4f734048e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d395fdd31cf493dbcd3f4f7026b1cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4f0ec8526b04e89827253b97ffcb72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8689087c1a244680bc9d8152efba780f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "731be2c045644958a2c68beb31dc1917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd504e178f4142549eeefee533e96b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ddc7a7a76e8436cbca8b78a0329cccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01a2556e7e524838b093beb2f3bf6cc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0fcce548a6464325bbee69d9af40ea46",
              "IPY_MODEL_bd931c3aed4646038ee5399f361f2d14",
              "IPY_MODEL_38e27e1775c3437195ec7cb3356d75bb"
            ]
          }
        },
        "01a2556e7e524838b093beb2f3bf6cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fcce548a6464325bbee69d9af40ea46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e835bdb721c4d6f931d0f2042821a7b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff43f7e961f14eac90d2010d421d11a3"
          }
        },
        "bd931c3aed4646038ee5399f361f2d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a9ed3001b7841aba4ec8bfb0c84e667",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7400cedd864846dfa5b8971d03b26351"
          }
        },
        "38e27e1775c3437195ec7cb3356d75bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1367ab5cc8d8447dbae157246f7b39d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 645kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47761ac20bf4467eba9e576820dfdd80"
          }
        },
        "4e835bdb721c4d6f931d0f2042821a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff43f7e961f14eac90d2010d421d11a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a9ed3001b7841aba4ec8bfb0c84e667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7400cedd864846dfa5b8971d03b26351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1367ab5cc8d8447dbae157246f7b39d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47761ac20bf4467eba9e576820dfdd80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlordier/colabs/blob/main/model6(Personality_Prediction)_Notebook5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oIMaxsVHIzp",
        "outputId": "e81002d2-8d44-4e30-a679-8ba4a63adb73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'personality-prediction'...\n",
            "remote: Enumerating objects: 818, done.\u001b[K\n",
            "remote: Counting objects: 100% (818/818), done.\u001b[K\n",
            "remote: Compressing objects: 100% (424/424), done.\u001b[K\n",
            "remote: Total 818 (delta 501), reused 659 (delta 376), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (818/818), 50.57 MiB | 11.03 MiB/s, done.\n",
            "Resolving deltas: 100% (501/501), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yashsmehta/personality-prediction.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install preprocessor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WdaqZi_JupI",
        "outputId": "2e0b336d-8d51-40dc-ba06-66195f4891ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting preprocessor\n",
            "  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n",
            "Building wheels for collected packages: preprocessor\n",
            "  Building wheel for preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4477 sha256=b3cba6ade753511f01be628dcea13ce040c4173412db26864e013e90570a9be8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/b7/36/aa37256db62b4bfd35a6f1b5536e9ba843f257b79dcbf3d5f1\n",
            "Successfully built preprocessor\n",
            "Installing collected packages: preprocessor\n",
            "Successfully installed preprocessor-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP_psycho_features based Personality Prediction**"
      ],
      "metadata": {
        "id": "0S5y_K8xr6-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_and_process(path):\n",
        "    arff = open(path, \"r\")\n",
        "    attributes = []\n",
        "    values = []\n",
        "    is_attr = True\n",
        "    arff.readline()\n",
        "    arff.readline()\n",
        "    while is_attr:\n",
        "        line = arff.readline()\n",
        "        if len(line.split()) == 0:\n",
        "            is_attr = False\n",
        "            continue\n",
        "        type = line.split()[0]\n",
        "        attr = \" \".join(line.split()[1:])\n",
        "        if type == \"@attribute\":\n",
        "            attributes.append(attr)\n",
        "        else:\n",
        "            is_attr = False\n",
        "    for line in arff.readlines():\n",
        "        if len(line.split(\",\")) < 10:\n",
        "            continue\n",
        "        else:\n",
        "            components = line.split(\",\")\n",
        "            values.append(components)\n",
        "            name = components[0].replace(\"'\", \"\").split(\"\\\\\\\\\")[-1]\n",
        "            values[-1][0] = name\n",
        "    df = pd.DataFrame(columns=attributes, data=values)\n",
        "    df[\"idx\"] = [int(re.sub(\"id_\", \"\", i)) for i in df[df.columns[0]]]\n",
        "    df = df.drop(df.columns[0], axis=1)\n",
        "    df = df.set_index([\"idx\"])\n",
        "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    df = df.sort_index()\n",
        "    return df\n",
        "\n",
        "\n",
        "def sentence_preprocess(sentence):\n",
        "    sentence = p.clean(sentence)\n",
        "    # Remove hyperlinks\n",
        "    sentence = re.sub(r\"http\\S+\", \" \", sentence)\n",
        "    # Remove punctuations and numbers\n",
        "    # sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    sentence = re.sub(\"[^a-zA-Z.?!,]\", \" \", sentence)\n",
        "    # Single character removal (except I)\n",
        "    sentence = re.sub(r\"\\s+[a-zA-HJ-Z]\\s+\", \" \", sentence)\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def load_features(dir, dataset):\n",
        "    idx = \"id\"\n",
        "    if dataset == \"kaggle\":\n",
        "        drop_cols = [\n",
        "            \"BROWN-FREQ numeric\",\n",
        "            \"K-F-FREQ numeric\",\n",
        "            \"K-F-NCATS numeric\",\n",
        "            \"K-F-NSAMP numeric\",\n",
        "            \"T-L-FREQ numeric\",\n",
        "            \"Extraversion numeric\",\n",
        "            \"'Emotional stability' numeric\",\n",
        "            \"Agreeableness numeric\",\n",
        "            \"Conscientiousness numeric\",\n",
        "            \"'Openness to experience' numeric\",\n",
        "        ]\n",
        "        mairesse = read_and_process(dir + dataset + \"_mairesse_labeled.arff\")\n",
        "        mairesse = mairesse.drop(drop_cols, axis=1)\n",
        "    elif dataset == \"essays\":\n",
        "        idx = \"#AUTHID\"\n",
        "        mairesse = pd.read_csv(dir + dataset + \"_mairesse_labeled.csv\")\n",
        "        mairesse = mairesse.set_index(mairesse.columns[0])\n",
        "    nrc = pd.read_csv(dir + dataset + \"_nrc.csv\").set_index([idx])\n",
        "    # nrc = nrc.sort_values(by=['id'])\n",
        "    # nrc = nrc.drop(['id'], axis=1)\n",
        "    nrc_vad = pd.read_csv(dir + dataset + \"_nrc_vad.csv\").set_index([idx])\n",
        "    # nrc_vad = nrc_vad.sort_values(by=['id'])\n",
        "    # nrc_vad = nrc_vad.drop(['id'], axis=1)\n",
        "    # affectivespace = pd.read_csv(dir + 'essays_affectivespace.csv').set_index(['#AUTHID'])\n",
        "    # hourglass = pd.read_csv(dir + dataset + '_hourglass.csv').set_index([idx])\n",
        "    readability = pd.read_csv(dir + dataset + \"_readability.csv\").set_index([idx])\n",
        "\n",
        "    return [nrc, nrc_vad, readability, mairesse]\n",
        "\n",
        "def get_psycholinguist_data(dump_data, dataset, feature_flags):\n",
        "    features = load_features(\n",
        "        \"/content/personality-prediction/data/\" + dataset + \"/psycholinguist_features/\", dataset\n",
        "    )\n",
        "\n",
        "    first = 1\n",
        "    for feature, feature_flag in zip(features, feature_flags):\n",
        "        if feature_flag:\n",
        "            if first:\n",
        "                df = feature\n",
        "                first = 0\n",
        "            else:\n",
        "                df = pd.merge(df, feature, left_index=True, right_index=True)\n",
        "    if dataset == \"essays\":\n",
        "        labels = dump_data[[\"user\", \"EXT\", \"NEU\", \"AGR\", \"CON\", \"OPN\"]]\n",
        "    if dataset == \"kaggle\":\n",
        "        labels = dump_data[[\"user\", \"E\", \"N\", \"F\", \"J\"]]\n",
        "    labels = labels.set_index(\"user\")\n",
        "    if dataset == \"kaggle\":\n",
        "        labels.index = pd.to_numeric(labels.index, errors=\"coerce\")\n",
        "        df.index = pd.to_numeric(df.index, errors=\"coerce\")\n",
        "    merged = pd.merge(df, labels, left_index=True, right_index=True).fillna(0)\n",
        "    label_size = labels.shape[1]\n",
        "    data = merged[merged.columns[: (-1 * label_size)]].values\n",
        "    full_targets = merged[merged.columns[(-1 * label_size) :]].values\n",
        "    feature_names = merged.columns\n",
        "    return data, full_targets, feature_names, merged\n",
        "import os\n",
        "# importing sys\n",
        "import sys\n",
        "sys.path.insert(0, '/content/personality-prediction')\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import utils.gen_utils as utils\n",
        "import utils.dataset_processors as dataset_processors\n",
        "#import utils.linguistic_features_utils as feature_utils\n",
        "\n",
        "\n",
        "def get_inputs(dataset):\n",
        "    \"\"\"Read data from metafeature files and prepare for training.\"\"\"\n",
        "\n",
        "    nrc, nrc_vad, readability, mairesse = [True, True, True, True]\n",
        "    feature_flags = [nrc, nrc_vad, readability, mairesse]\n",
        "    if dataset == \"essays\":\n",
        "        dump_data = dataset_processors.load_essays_df(\"/content/personality-prediction/data/essays/essays.csv\")\n",
        "        trait_labels = [\"EXT\", \"NEU\", \"AGR\", \"CON\", \"OPN\"]\n",
        "    elif dataset == \"kaggle\":\n",
        "        dump_data = dataset_processors.load_Kaggle_df(\"/content/personality-prediction/data/kaggle/kaggle.csv\")\n",
        "        trait_labels = [\"E\", \"N\", \"F\", \"J\"]\n",
        "    print(\"dataset loaded! Getting psycholinguistic features...\")\n",
        "    inputs, full_targets, _, _ = get_psycholinguist_data(\n",
        "        dump_data, dataset, feature_flags\n",
        "    )\n",
        "    inputs = np.array(inputs)\n",
        "    full_targets = np.array(full_targets)\n",
        "\n",
        "    return inputs, full_targets, trait_labels\n",
        "\n",
        "\n",
        "def training(inputs, full_targets, trait_labels):\n",
        "    \"\"\"Train MLP model for each trait on 10-fold corss-validtion.\"\"\"\n",
        "    n_splits = 10\n",
        "    expdata = {}\n",
        "    expdata[\"acc\"], expdata[\"trait\"], expdata[\"fold\"] = [], [], []\n",
        "\n",
        "    for trait_idx in range(full_targets.shape[1]):\n",
        "        # convert targets to one-hot encoding\n",
        "        targets = full_targets[:, trait_idx]\n",
        "        expdata[\"trait\"].extend([trait_labels[trait_idx]] * n_splits)\n",
        "        expdata[\"fold\"].extend(np.arange(1, n_splits + 1))\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
        "        k = -1\n",
        "\n",
        "        for train_index, test_index in skf.split(inputs, targets):\n",
        "            x_train, x_test = inputs[train_index], inputs[test_index]\n",
        "            y_train, y_test = targets[train_index], targets[test_index]\n",
        "            # converting to one-hot embedding\n",
        "            y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "            y_test = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
        "            model = tf.keras.models.Sequential()\n",
        "\n",
        "            # define the neural network architecture\n",
        "            model.add(\n",
        "                tf.keras.layers.Dense(50, input_dim=features_dim, activation=\"relu\")\n",
        "            )\n",
        "            model.add(tf.keras.layers.Dense(n_classes))\n",
        "\n",
        "            k += 1\n",
        "            model.compile(\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=[\"mse\", \"accuracy\"],\n",
        "            )\n",
        "            history = model.fit(\n",
        "                x_train,\n",
        "                y_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=(x_test, y_test),\n",
        "                verbose=0,\n",
        "            )\n",
        "            expdata[\"acc\"].append(100 * max(history.history[\"val_accuracy\"]))\n",
        "    print(expdata)\n",
        "    df = pd.DataFrame.from_dict(expdata)\n",
        "\n",
        "    preds=model.predict(x_test)\n",
        "\n",
        "    return df,preds, y_test\n",
        "\n",
        "\n",
        "\n",
        "def logging(df, log_expdata=True):\n",
        "    \"\"\"Save results and each models config and hyper parameters.\"\"\"\n",
        "    (\n",
        "        df[\"network\"],\n",
        "        df[\"dataset\"],\n",
        "        df[\"lr\"],\n",
        "        df[\"batch_size\"],\n",
        "        df[\"epochs\"],\n",
        "        df[\"model_input\"],\n",
        "        df[\"embed\"],\n",
        "        df[\"layer\"],\n",
        "        df[\"mode\"],\n",
        "        df[\"embed_mode\"],\n",
        "        df[\"jobid\"],\n",
        "    ) = (\n",
        "        network,\n",
        "        dataset,\n",
        "        lr,\n",
        "        batch_size,\n",
        "        epochs,\n",
        "        MODEL_INPUT,\n",
        "        embed,\n",
        "        layer,\n",
        "        mode,\n",
        "        embed_mode,\n",
        "        jobid,\n",
        "    )\n",
        "\n",
        "    pd.set_option(\"display.max_columns\", None)\n",
        "    print(df.head(5))\n",
        "\n",
        "    # save the results of our experiment\n",
        "    if log_expdata:\n",
        "        Path(path).mkdir(parents=True, exist_ok=True)\n",
        "        if not os.path.exists(path + \"expdata.csv\"):\n",
        "            df.to_csv(path + \"expdata.csv\", mode=\"a\", header=True)\n",
        "        else:\n",
        "            df.to_csv(path + \"expdata.csv\", mode=\"a\", header=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sys.argv=['']\n",
        "    del sys\n",
        "    (\n",
        "        inp_dir,\n",
        "        dataset,\n",
        "        lr,\n",
        "        batch_size,\n",
        "        epochs,\n",
        "        log_expdata,\n",
        "        embed,\n",
        "        layer,\n",
        "        mode,\n",
        "        embed_mode,\n",
        "        jobid,\n",
        "    ) = utils.parse_args()\n",
        "\n",
        "    features_dim = 123\n",
        "    MODEL_INPUT = \"psycholinguist_features\"\n",
        "    layer = \"\"\n",
        "    path = \"explogs/\"\n",
        "    n_classes = 2\n",
        "    network = \"MLP\"\n",
        "    print(network)\n",
        "\n",
        "    np.random.seed(jobid)\n",
        "    tf.random.set_seed(jobid)\n",
        "\n",
        "    start = time.time()\n",
        "    inputs, full_targets, trait_labels = get_inputs(dataset)\n",
        "    print(\"starting k-fold cross validation...\")\n",
        "    df,preds,y_test = training(inputs, full_targets, trait_labels)\n",
        "    logging(df, log_expdata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvPGy4DsI0ha",
        "outputId": "e374c8bb-0648-402d-a2b3-7be54e009fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP\n",
            "EXT :  1    1275\n",
            "0    1192\n",
            "Name: EXT, dtype: int64\n",
            "NEU :  1    1234\n",
            "0    1233\n",
            "Name: NEU, dtype: int64\n",
            "AGR :  1    1309\n",
            "0    1158\n",
            "Name: AGR, dtype: int64\n",
            "CON :  1    1254\n",
            "0    1213\n",
            "Name: CON, dtype: int64\n",
            "OPN :  1    1271\n",
            "0    1196\n",
            "Name: OPN, dtype: int64\n",
            "dataset loaded! Getting psycholinguistic features...\n",
            "starting k-fold cross validation...\n",
            "{'acc': [58.29959511756897, 55.87044358253479, 60.323888063430786, 58.29959511756897, 57.08501935005188, 56.27530217170715, 50.607287883758545, 51.21951103210449, 58.53658318519592, 55.28455376625061, 56.27530217170715, 62.3481810092926, 61.94332242012024, 59.51417088508606, 61.94332242012024, 64.7773265838623, 64.7773265838623, 59.75610017776489, 56.91056847572327, 58.13007950782776, 59.51417088508606, 48.178136348724365, 55.06072640419006, 67.20647811889648, 55.06072640419006, 52.226722240448, 58.70445370674133, 59.75610017776489, 58.94308686256409, 52.84552574157715, 59.109312295913696, 56.68016076087952, 57.894736528396606, 56.27530217170715, 55.87044358253479, 52.226722240448, 68.01619529724121, 56.91056847572327, 54.47154641151428, 56.09756112098694, 59.109312295913696, 58.29959511756897, 57.894736528396606, 61.538463830947876, 62.75303363800049, 61.538463830947876, 55.46558499336243, 61.38211488723755, 58.94308686256409, 63.008129596710205], 'trait': ['EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN'], 'fold': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
            "         acc trait  fold network dataset      lr  batch_size  epochs  \\\n",
            "0  58.299595   EXT     1     MLP  essays  0.0005          32      10   \n",
            "1  55.870444   EXT     2     MLP  essays  0.0005          32      10   \n",
            "2  60.323888   EXT     3     MLP  essays  0.0005          32      10   \n",
            "3  58.299595   EXT     4     MLP  essays  0.0005          32      10   \n",
            "4  57.085019   EXT     5     MLP  essays  0.0005          32      10   \n",
            "\n",
            "               model_input      embed layer      mode embed_mode  jobid  \n",
            "0  psycholinguist_features  bert-base        512_head        cls      0  \n",
            "1  psycholinguist_features  bert-base        512_head        cls      0  \n",
            "2  psycholinguist_features  bert-base        512_head        cls      0  \n",
            "3  psycholinguist_features  bert-base        512_head        cls      0  \n",
            "4  psycholinguist_features  bert-base        512_head        cls      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual=[]\n",
        "y_pred=[]\n",
        "for i in range(len(preds)):\n",
        "  y_actual.append(np.argmax(y_test[i]))\n",
        "  y_pred.append(np.argmax(preds[i]))\n",
        "import matplotlib.pyplot as plt1\n",
        " \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt1.cm.Greens):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    import itertools\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        " \n",
        " \n",
        "    plt1.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt1.title(title)\n",
        "    plt1.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt1.xticks(tick_marks, classes, rotation=45)\n",
        "    plt1.yticks(tick_marks, classes)\n",
        " \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt1.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        " \n",
        "    plt1.ylabel('True label')\n",
        "    plt1.xlabel('Predicted label')\n",
        "    plt1.cm\n",
        "    plt1.show()\n",
        "cnf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "np.set_printoptions(precision=2)\n",
        " \n",
        "# Plot non-normalized confusion matrix\n",
        "plt1.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['0', '1'],\n",
        "                      \n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "jEVsWAOgrJQP",
        "outputId": "504a3a66-ad68-4150-ac8c-a2265bf634e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BERT FEATURE EXTRACTION**"
      ],
      "metadata": {
        "id": "38czPMt_p87h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install tweet-preprocessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "991ymwEpfpp5",
        "outputId": "f147e24f-3b13-414f-cd50-76250cc803f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# importing sys\n",
        "import sys\n",
        "sys.path.insert(0, '/content/personality-prediction')\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import pickle\n",
        "import re\n",
        "import time\n",
        "from datetime import timedelta\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "#from transformers import *\n",
        "import transformers\n",
        "import preprocessor\n",
        "import utils.gen_utils as utils\n",
        "from utils.data_utils import MyMapDataset\n",
        "import os\n",
        "from pathlib import Path\n",
        "from transformers import BertModel, AlbertModel, BertTokenizer\n",
        "sys.path.insert(0, os.getcwd())\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import preprocessor as p\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import preprocessor as p\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "#from transformers import *\n",
        "import math\n",
        "\n",
        "from utils.author_100recent import get_100_recent_posts\n",
        "import utils.dataset_processors as dataset_processors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import preprocessor as p\n",
        "import math\n",
        "\n",
        "\n",
        "def preprocess_text(sentence):\n",
        "    # remove hyperlinks, hashtags, smileys, emojies\n",
        "    sentence = p.clean(sentence)\n",
        "    # Remove hyperlinks\n",
        "    sentence = re.sub(r\"http\\S+\", \" \", sentence)\n",
        "    # Remove punctuations and numbers\n",
        "    # sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    # sentence = re.sub('[^a-zA-Z.?!,]', ' ', sentence)\n",
        "    # Single character removal (except I)\n",
        "    # sentence = re.sub(r\"\\s+[a-zA-HJ-Z]\\s+\", ' ', sentence)\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\|\\|\\|\", \" \", sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def load_essays_df(datafile):\n",
        "    with open(datafile, \"rt\") as csvf:\n",
        "        csvreader = csv.reader(csvf, delimiter=\",\", quotechar='\"')\n",
        "        first_line = True\n",
        "        df = pd.DataFrame(\n",
        "            columns=[\"user\", \"text\", \"token_len\", \"EXT\", \"NEU\", \"AGR\", \"CON\", \"OPN\"]\n",
        "        )\n",
        "        for line in csvreader:\n",
        "            if first_line:\n",
        "                first_line = False\n",
        "                continue\n",
        "\n",
        "            text = line[1]\n",
        "            df = df.append(\n",
        "                {\n",
        "                    \"user\": line[0],\n",
        "                    \"text\": text,\n",
        "                    \"token_len\": 0,\n",
        "                    \"EXT\": 1 if line[2].lower() == \"y\" else 0,\n",
        "                    \"NEU\": 1 if line[3].lower() == \"y\" else 0,\n",
        "                    \"AGR\": 1 if line[4].lower() == \"y\" else 0,\n",
        "                    \"CON\": 1 if line[5].lower() == \"y\" else 0,\n",
        "                    \"OPN\": 1 if line[6].lower() == \"y\" else 0,\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "    print(\"EXT : \", df[\"EXT\"].value_counts())\n",
        "    print(\"NEU : \", df[\"NEU\"].value_counts())\n",
        "    print(\"AGR : \", df[\"AGR\"].value_counts())\n",
        "    print(\"CON : \", df[\"CON\"].value_counts())\n",
        "    print(\"OPN : \", df[\"OPN\"].value_counts())\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def essays_embeddings(datafile, tokenizer, token_length, mode):\n",
        "    targets = []\n",
        "    input_ids = []\n",
        "\n",
        "    df = load_essays_df(datafile)\n",
        "    cnt = 0\n",
        "\n",
        "    # sorting all essays in ascending order of their length\n",
        "    for ind in df.index:\n",
        "        tokens = tokenizer.tokenize(df[\"text\"][ind])\n",
        "        df.at[ind, \"token_len\"] = len(tokens)\n",
        "\n",
        "    df.sort_values(by=[\"token_len\", \"user\"], inplace=True, ascending=True)\n",
        "    tmp_df = df[\"user\"]\n",
        "    tmp_df.to_csv(\"/content/personality-prediction/data/essays/author_id_order.csv\", index_label=\"order\")\n",
        "    print(df[\"token_len\"].mean())\n",
        "\n",
        "    for ii in range(len(df)):\n",
        "        text = preprocess_text(df[\"text\"][ii])\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "\n",
        "        if mode == \"normal\" or mode == \"512_head\":\n",
        "            input_ids.append(\n",
        "                tokenizer.encode(\n",
        "                    tokens,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "            )\n",
        "        elif mode == \"512_tail\":\n",
        "            input_ids.append(\n",
        "                tokenizer.encode(\n",
        "                    tokens[-(token_length - 2) :],\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "            )\n",
        "        elif mode == \"256_head_tail\":\n",
        "            input_ids.append(\n",
        "                tokenizer.encode(\n",
        "                    tokens[: (token_length - 1)] + tokens[-(token_length - 1) :],\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        elif mode == \"docbert\":\n",
        "            docmax_len = 2048\n",
        "            subdoc_len = 512\n",
        "            max_subdoc_num = docmax_len // subdoc_len\n",
        "            subdoc_tokens = [\n",
        "                tokens[i : i + subdoc_len] for i in range(0, len(tokens), subdoc_len)\n",
        "            ][:max_subdoc_num]\n",
        "            # print(subdoc_tokens)\n",
        "            token_ids = [\n",
        "                tokenizer.encode(\n",
        "                    x,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "                for x in subdoc_tokens\n",
        "            ]\n",
        "            # print(token_ids)\n",
        "            token_ids = np.array(token_ids).astype(int)\n",
        "\n",
        "            buffer_len = docmax_len // subdoc_len - token_ids.shape[0]\n",
        "            # print(buffer_len)\n",
        "            tmp = np.full(shape=(buffer_len, token_length), fill_value=0, dtype=int)\n",
        "            token_ids = np.concatenate((token_ids, tmp), axis=0)\n",
        "\n",
        "            input_ids.append(token_ids)\n",
        "\n",
        "        targets.append(\n",
        "            [df[\"EXT\"][ii], df[\"NEU\"][ii], df[\"AGR\"][ii], df[\"CON\"][ii], df[\"OPN\"][ii]]\n",
        "        )\n",
        "        cnt += 1\n",
        "\n",
        "    author_ids = np.array(df.index)\n",
        "    print(\"loaded all input_ids and targets from the data file!\")\n",
        "    return author_ids, input_ids, targets\n",
        "\n",
        "\n",
        "def load_Kaggle_df(datafile):\n",
        "    with open(datafile, \"rt\", encoding=\"utf-8\") as csvf:\n",
        "        csvreader = csv.reader(csvf, delimiter=\",\", quotechar='\"')\n",
        "        first_line = True\n",
        "        df = pd.DataFrame(columns=[\"user\", \"text\", \"E\", \"N\", \"F\", \"J\"])\n",
        "        for line in csvreader:\n",
        "            if first_line:\n",
        "                first_line = False\n",
        "                continue\n",
        "\n",
        "            text = line[1]\n",
        "\n",
        "            df = df.append(\n",
        "                {\n",
        "                    \"user\": line[3],\n",
        "                    \"text\": text,\n",
        "                    \"E\": 1 if line[0][0] == \"E\" else 0,\n",
        "                    \"N\": 1 if line[0][1] == \"N\" else 0,\n",
        "                    \"F\": 1 if line[0][2] == \"F\" else 0,\n",
        "                    \"J\": 1 if line[0][3] == \"J\" else 0,\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "    print(\"E : \", df[\"E\"].value_counts())\n",
        "    print(\"N : \", df[\"N\"].value_counts())\n",
        "    print(\"F : \", df[\"F\"].value_counts())\n",
        "    print(\"J : \", df[\"J\"].value_counts())\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def kaggle_embeddings(datafile, tokenizer, token_length):\n",
        "    hidden_features = []\n",
        "    targets = []\n",
        "    token_len = []\n",
        "    input_ids = []\n",
        "    author_ids = []\n",
        "\n",
        "    df = load_Kaggle_df(datafile)\n",
        "    cnt = 0\n",
        "    for ind in df.index:\n",
        "\n",
        "        text = preprocess_text(df[\"text\"][ind])\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_len.append(len(tokens))\n",
        "        token_ids = tokenizer.encode(\n",
        "            tokens,\n",
        "            add_special_tokens=True,\n",
        "            max_length=token_length,\n",
        "            pad_to_max_length=True,\n",
        "        )\n",
        "        if cnt < 10:\n",
        "            print(tokens[:10])\n",
        "\n",
        "        input_ids.append(token_ids)\n",
        "        targets.append([df[\"E\"][ind], df[\"N\"][ind], df[\"F\"][ind], df[\"J\"][ind]])\n",
        "        author_ids.append(int(df[\"user\"][ind]))\n",
        "        cnt += 1\n",
        "\n",
        "    print(\"average length : \", int(np.mean(token_len)))\n",
        "    author_ids = np.array(author_ids)\n",
        "\n",
        "    return author_ids, input_ids, targets\n",
        "\n",
        "\n",
        "class MyMapDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, token_length, DEVICE, mode):\n",
        "        if dataset == \"essays\":\n",
        "            datafile = \"/content/personality-prediction/data/essays/essays.csv\"\n",
        "            author_ids, input_ids, targets = essays_embeddings(\n",
        "                datafile, tokenizer, token_length, mode\n",
        "            )\n",
        "        elif dataset == \"kaggle\":\n",
        "            datafile = \"/content/personality-prediction/data/kaggle/kaggle.csv\"\n",
        "            author_ids, input_ids, targets = kaggle_embeddings(\n",
        "                datafile, tokenizer, token_length\n",
        "            )\n",
        "        elif dataset == \"pandora\":\n",
        "            author_ids, input_ids, targets = pandora_embeddings(\n",
        "                datafile, tokenizer, token_length\n",
        "            )\n",
        "\n",
        "        author_ids = torch.from_numpy(np.array(author_ids)).long().to(DEVICE)\n",
        "        input_ids = torch.from_numpy(np.array(input_ids)).long().to(DEVICE)\n",
        "        targets = torch.from_numpy(np.array(targets))\n",
        "\n",
        "        if dataset == \"pandora\":\n",
        "            targets = targets.float().to(DEVICE)\n",
        "        else:\n",
        "            targets = targets.long().to(DEVICE)\n",
        "\n",
        "        self.author_ids = author_ids\n",
        "        self.input_ids = input_ids\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.author_ids[idx], self.input_ids[idx], self.targets[idx])\n",
        "\n",
        "def preprocess_text(sentence):\n",
        "    # remove hyperlinks, hashtags, smileys, emojies\n",
        "    sentence = p.clean(sentence)\n",
        "    # Remove hyperlinks\n",
        "    sentence = re.sub(r\"http\\S+\", \" \", sentence)\n",
        "    # Remove punctuations and numbers\n",
        "    # sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    # sentence = re.sub('[^a-zA-Z.?!,]', ' ', sentence)\n",
        "    # Single character removal (except I)\n",
        "    # sentence = re.sub(r\"\\s+[a-zA-HJ-Z]\\s+\", ' ', sentence)\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\|\\|\\|\", \" \", sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def load_essays_df(datafile):\n",
        "    with open(datafile, \"rt\") as csvf:\n",
        "        csvreader = csv.reader(csvf, delimiter=\",\", quotechar='\"')\n",
        "        first_line = True\n",
        "        df = pd.DataFrame(\n",
        "            columns=[\"user\", \"text\", \"token_len\", \"EXT\", \"NEU\", \"AGR\", \"CON\", \"OPN\"]\n",
        "        )\n",
        "        for line in csvreader:\n",
        "            if first_line:\n",
        "                first_line = False\n",
        "                continue\n",
        "\n",
        "            text = line[1]\n",
        "            df = df.append(\n",
        "                {\n",
        "                    \"user\": line[0],\n",
        "                    \"text\": text,\n",
        "                    \"token_len\": 0,\n",
        "                    \"EXT\": 1 if line[2].lower() == \"y\" else 0,\n",
        "                    \"NEU\": 1 if line[3].lower() == \"y\" else 0,\n",
        "                    \"AGR\": 1 if line[4].lower() == \"y\" else 0,\n",
        "                    \"CON\": 1 if line[5].lower() == \"y\" else 0,\n",
        "                    \"OPN\": 1 if line[6].lower() == \"y\" else 0,\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "    print(\"EXT : \", df[\"EXT\"].value_counts())\n",
        "    print(\"NEU : \", df[\"NEU\"].value_counts())\n",
        "    print(\"AGR : \", df[\"AGR\"].value_counts())\n",
        "    print(\"CON : \", df[\"CON\"].value_counts())\n",
        "    print(\"OPN : \", df[\"OPN\"].value_counts())\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def essays_embeddings(datafile, tokenizer, token_length, mode):\n",
        "    targets = []\n",
        "    input_ids = []\n",
        "\n",
        "    df = load_essays_df(datafile)\n",
        "    cnt = 0\n",
        "\n",
        "    # sorting all essays in ascending order of their length\n",
        "    for ind in df.index:\n",
        "        tokens = tokenizer.tokenize(df[\"text\"][ind])\n",
        "        df.at[ind, \"token_len\"] = len(tokens)\n",
        "\n",
        "    df.sort_values(by=[\"token_len\", \"user\"], inplace=True, ascending=True)\n",
        "    tmp_df = df[\"user\"]\n",
        "    tmp_df.to_csv(\"/content/personality-prediction/data/essays/author_id_order.csv\", index_label=\"order\")\n",
        "    print(df[\"token_len\"].mean())\n",
        "\n",
        "    for ii in range(len(df)):\n",
        "        text = preprocess_text(df[\"text\"][ii])\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "\n",
        "        if mode == \"normal\" or mode == \"512_head\":\n",
        "            input_ids.append(\n",
        "                tokenizer.encode(\n",
        "                    tokens,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "            )\n",
        "        elif mode == \"512_tail\":\n",
        "            input_ids.append(\n",
        "                tokenizer.encode(\n",
        "                    tokens[-(token_length - 2) :],\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "            )\n",
        "        elif mode == \"256_head_tail\":\n",
        "            input_ids.append(\n",
        "                tokenizer.encode(\n",
        "                    tokens[: (token_length - 1)] + tokens[-(token_length - 1) :],\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        elif mode == \"docbert\":\n",
        "            docmax_len = 2048\n",
        "            subdoc_len = 512\n",
        "            max_subdoc_num = docmax_len // subdoc_len\n",
        "            subdoc_tokens = [\n",
        "                tokens[i : i + subdoc_len] for i in range(0, len(tokens), subdoc_len)\n",
        "            ][:max_subdoc_num]\n",
        "            # print(subdoc_tokens)\n",
        "            token_ids = [\n",
        "                tokenizer.encode(\n",
        "                    x,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=token_length,\n",
        "                    pad_to_max_length=True,\n",
        "                )\n",
        "                for x in subdoc_tokens\n",
        "            ]\n",
        "            # print(token_ids)\n",
        "            token_ids = np.array(token_ids).astype(int)\n",
        "\n",
        "            buffer_len = docmax_len // subdoc_len - token_ids.shape[0]\n",
        "            # print(buffer_len)\n",
        "            tmp = np.full(shape=(buffer_len, token_length), fill_value=0, dtype=int)\n",
        "            token_ids = np.concatenate((token_ids, tmp), axis=0)\n",
        "\n",
        "            input_ids.append(token_ids)\n",
        "\n",
        "        targets.append(\n",
        "            [df[\"EXT\"][ii], df[\"NEU\"][ii], df[\"AGR\"][ii], df[\"CON\"][ii], df[\"OPN\"][ii]]\n",
        "        )\n",
        "        cnt += 1\n",
        "\n",
        "    author_ids = np.array(df.index)\n",
        "    print(\"loaded all input_ids and targets from the data file!\")\n",
        "    return author_ids, input_ids, targets\n",
        "\n",
        "\n",
        "def load_Kaggle_df(datafile):\n",
        "    with open(datafile, \"rt\", encoding=\"utf-8\") as csvf:\n",
        "        csvreader = csv.reader(csvf, delimiter=\",\", quotechar='\"')\n",
        "        first_line = True\n",
        "        df = pd.DataFrame(columns=[\"user\", \"text\", \"E\", \"N\", \"F\", \"J\"])\n",
        "        for line in csvreader:\n",
        "            if first_line:\n",
        "                first_line = False\n",
        "                continue\n",
        "\n",
        "            text = line[1]\n",
        "\n",
        "            df = df.append(\n",
        "                {\n",
        "                    \"user\": line[3],\n",
        "                    \"text\": text,\n",
        "                    \"E\": 1 if line[0][0] == \"E\" else 0,\n",
        "                    \"N\": 1 if line[0][1] == \"N\" else 0,\n",
        "                    \"F\": 1 if line[0][2] == \"F\" else 0,\n",
        "                    \"J\": 1 if line[0][3] == \"J\" else 0,\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )\n",
        "\n",
        "    print(\"E : \", df[\"E\"].value_counts())\n",
        "    print(\"N : \", df[\"N\"].value_counts())\n",
        "    print(\"F : \", df[\"F\"].value_counts())\n",
        "    print(\"J : \", df[\"J\"].value_counts())\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def kaggle_embeddings(datafile, tokenizer, token_length):\n",
        "    hidden_features = []\n",
        "    targets = []\n",
        "    token_len = []\n",
        "    input_ids = []\n",
        "    author_ids = []\n",
        "\n",
        "    df = load_Kaggle_df(datafile)\n",
        "    cnt = 0\n",
        "    for ind in df.index:\n",
        "\n",
        "        text = preprocess_text(df[\"text\"][ind])\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_len.append(len(tokens))\n",
        "        token_ids = tokenizer.encode(\n",
        "            tokens,\n",
        "            add_special_tokens=True,\n",
        "            max_length=token_length,\n",
        "            pad_to_max_length=True,\n",
        "        )\n",
        "        if cnt < 10:\n",
        "            print(tokens[:10])\n",
        "\n",
        "        input_ids.append(token_ids)\n",
        "        targets.append([df[\"E\"][ind], df[\"N\"][ind], df[\"F\"][ind], df[\"J\"][ind]])\n",
        "        author_ids.append(int(df[\"user\"][ind]))\n",
        "        cnt += 1\n",
        "\n",
        "    print(\"average length : \", int(np.mean(token_len)))\n",
        "    author_ids = np.array(author_ids)\n",
        "\n",
        "    return author_ids, input_ids, targets\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    print(\"GPU found (\", torch.cuda.get_device_name(torch.cuda.current_device()), \")\")\n",
        "    torch.cuda.set_device(torch.cuda.current_device())\n",
        "    print(\"num device avail: \", torch.cuda.device_count())\n",
        "\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"running on cpu\")\n",
        "\n",
        "\n",
        "def extract_bert_features(input_ids, mode, n_hl):\n",
        "    \"\"\"Extract bert embedding for each input.\"\"\"\n",
        "    if mode == \"docbert\":\n",
        "        # print(input_ids.shape)\n",
        "        tmphidden_features = []\n",
        "        input_ids = input_ids.permute(1, 0, 2)\n",
        "\n",
        "        for jj in range(input_ids.shape[0]):\n",
        "            tmp = []\n",
        "            if input_ids[jj][0][0] == 0:\n",
        "                break\n",
        "\n",
        "            bert_output = model(input_ids[jj])\n",
        "            for ii in range(n_hl):\n",
        "                if embed_mode == \"mean\":\n",
        "                    tmp.append((bert_output[2][ii + 1].cpu().numpy()).mean(axis=1))\n",
        "                elif embed_mode == \"cls\":\n",
        "                    tmp.append(bert_output[2][ii + 1][:, 0, :].cpu().numpy())\n",
        "\n",
        "            tmphidden_features.append(tmp)\n",
        "\n",
        "        tmphidden_features = np.array(tmphidden_features)\n",
        "        hidden_features.append(tmphidden_features.mean(axis=0))\n",
        "\n",
        "    else:\n",
        "        tmp = []\n",
        "        bert_output = model(input_ids)\n",
        "        # bert_output[2](this id gives all BERT outputs)[ii+1](which BERT layer)[:,0,:](taking the <CLS> output)\n",
        "\n",
        "        for ii in range(n_hl):\n",
        "            if embed_mode == \"cls\":\n",
        "                tmp.append(bert_output[2][ii + 1][:, 0, :].cpu().numpy())\n",
        "            elif embed_mode == \"mean\":\n",
        "                tmp.append((bert_output[2][ii + 1].cpu().numpy()).mean(axis=1))\n",
        "\n",
        "        hidden_features.append(np.array(tmp))\n",
        "        return hidden_features\n",
        "\n",
        "\n",
        "def get_model(embed):\n",
        "    # * Model          | Tokenizer          | Pretrained weights shortcut\n",
        "    # MODEL=(DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "    if embed == \"bert-base\":\n",
        "        n_hl = 12\n",
        "        hidden_dim = 768\n",
        "        MODEL = (BertModel, BertTokenizer, \"bert-base-uncased\")\n",
        "\n",
        "    elif embed == \"bert-large\":\n",
        "        n_hl = 24\n",
        "        hidden_dim = 1024\n",
        "        MODEL = (BertModel, BertTokenizer, \"bert-large-uncased\")\n",
        "\n",
        "    elif embed == \"albert-base\":\n",
        "        n_hl = 12\n",
        "        hidden_dim = 768\n",
        "        MODEL = (AlbertModel, AlbertTokenizer, \"albert-base-v2\")\n",
        "\n",
        "    elif embed == \"albert-large\":\n",
        "        n_hl = 24\n",
        "        hidden_dim = 1024\n",
        "        MODEL = (AlbertModel, AlbertTokenizer, \"albert-large-v2\")\n",
        "\n",
        "    model_class, tokenizer_class, pretrained_weights = MODEL\n",
        "\n",
        "    # load the LM model and tokenizer from the HuggingFace Transformers library\n",
        "    model = model_class.from_pretrained(\n",
        "        pretrained_weights, output_hidden_states=True\n",
        "    )  # output_attentions=False\n",
        "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights, do_lower_case=True)\n",
        "\n",
        "    return model, tokenizer, n_hl, hidden_dim\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sys.argv=['']\n",
        "    del sys\n",
        "    # argument extractor\n",
        "    (\n",
        "        dataset,\n",
        "        token_length,\n",
        "        batch_size,\n",
        "        embed,\n",
        "        op_dir,\n",
        "        mode,\n",
        "        embed_mode,\n",
        "    ) = utils.parse_args_extractor()\n",
        "    print(\n",
        "        \"{} | {} | {} | {} | {}\".format(dataset, embed, token_length, mode, embed_mode)\n",
        "    )\n",
        "    batch_size = int(32)\n",
        "    model, tokenizer, n_hl, hidden_dim = get_model(embed)\n",
        "\n",
        "    # create a class which can be passed to the pyTorch dataloader. responsible for returning tokenized and encoded values of the dataset\n",
        "    # this class will have __getitem__(self,idx) function which will return input_ids and target values\n",
        "\n",
        "    map_dataset = MyMapDataset(dataset, tokenizer, token_length, DEVICE, mode)\n",
        "\n",
        "    data_loader = DataLoader(\n",
        "        dataset=map_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    if DEVICE == torch.device(\"cuda\"):\n",
        "        model = model.cuda()\n",
        "        # model.parameters() returns a generator obj\n",
        "        # print('model loaded to gpu? ', next(model.parameters()).is_cuda)\n",
        "        print(\n",
        "            \"\\ngpu mem alloc: \", round(torch.cuda.memory_allocated() * 1e-9, 2), \" GB\"\n",
        "        )\n",
        "\n",
        "    print(\"starting to extract LM embeddings...\")\n",
        "\n",
        "    hidden_features = []\n",
        "    all_targets = []\n",
        "    all_author_ids = []\n",
        "\n",
        "    # get bert embedding for each input\n",
        "    for author_ids, input_ids, targets in data_loader:\n",
        "        with torch.no_grad():\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "            all_author_ids.append(author_ids.cpu().numpy())\n",
        "            extract_bert_features(input_ids, mode, n_hl)\n",
        "\n",
        "    Path(op_dir).mkdir(parents=True, exist_ok=True)\n",
        "    pkl_file_name = dataset + \"-\" + embed + \"-\" + embed_mode + \"-\" + mode + \".pkl\"\n",
        "\n",
        "    file = open(os.path.join(op_dir, pkl_file_name), \"wb\")\n",
        "    pickle.dump(zip(all_author_ids, hidden_features, all_targets), file)\n",
        "    file.close()\n",
        "\n",
        "    # print(timedelta(seconds=int(time.time() - start)), end=' ')\n",
        "    print(\"extracting embeddings for {} dataset: DONE!\".format(dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "750bbe8ea77449429e2e49c9b63f5892",
            "8e4e89f6f1fa4eaf8b4da68802310bee",
            "492c70e0281f4e9c9da08e79da0db614",
            "c5efa36eeb7443e6843640830e4bf361",
            "684900bc86a74fabbbd66e4825c17512",
            "0f0fab9813d7401b8e03098581cf3c54",
            "a8adafecee1e49b8b280c17567a584b6",
            "35f07f1bdb28476e8917d80d6b42a7de",
            "2c013a5b7c634f08b032decb064739e1",
            "99a8ee20ea124cbcb5c0129588d84dc1",
            "b25ab2bedf174cadad423b5eb404209d",
            "2c8ae835d3b3439da47b6ab6e9bc3e63",
            "c4a6d3341f354090a346a7c38039bcf1",
            "837652cd45934caf83bfad4d8c2226d3",
            "0bc795d4dca04b1c8b43f66e5386a4d7",
            "1e292d88fbf84621ab9b515c00437d5a",
            "b54970944f66436b81e51a42bdf37be1",
            "1a2bc33148c5417e8a1a33a192ff6586",
            "649b2c5f22e7445f9c3a9fc78f8e0dc5",
            "7bde5e24c8bc44fca8f1148329055cdd",
            "b51ae64795ac4cad939a9b30f606227c",
            "46ae8ea705db4881ba8c5ec56ffe08d1",
            "b30d62adc659440f8e4b418d263110df",
            "bed698ab83194b9f9aa5d1979090882a",
            "a123d45a2688436a83f6bc9970cdbf82",
            "5cd2c095c5c9469684268c034300b882",
            "31ec75b8d1414cda88fd4081e5e2ce6f",
            "4beef35a7db24bd9ab7b31a7c5c4d556",
            "811473abfd1247709101f7c7691f7de7",
            "af7ff4d504044cb4a9fd91008b06a8e1",
            "c09e2edebd224499a121a59f589adc7a",
            "f0c314bbef8d4f76b38584fd291ee265",
            "b7f3c45bda7d4c6f9b4ab97a98965dee",
            "99c42d0c77644c24bc9a7d956d5ed768",
            "03b88df1da0f4766afb9bd6c09b03eb5",
            "7f666bfb3a094f398233e2784020bc28",
            "efe654c96a314f458bbc5e78bb94d057",
            "6f0f9847e75f4d3c9b19fffeb28c1809",
            "ce7a742531c245bfa10f4e4f734048e8",
            "3d395fdd31cf493dbcd3f4f7026b1cb0",
            "d4f0ec8526b04e89827253b97ffcb72e",
            "8689087c1a244680bc9d8152efba780f",
            "731be2c045644958a2c68beb31dc1917",
            "fd504e178f4142549eeefee533e96b64",
            "8ddc7a7a76e8436cbca8b78a0329cccb",
            "01a2556e7e524838b093beb2f3bf6cc8",
            "0fcce548a6464325bbee69d9af40ea46",
            "bd931c3aed4646038ee5399f361f2d14",
            "38e27e1775c3437195ec7cb3356d75bb",
            "4e835bdb721c4d6f931d0f2042821a7b",
            "ff43f7e961f14eac90d2010d421d11a3",
            "5a9ed3001b7841aba4ec8bfb0c84e667",
            "7400cedd864846dfa5b8971d03b26351",
            "1367ab5cc8d8447dbae157246f7b39d5",
            "47761ac20bf4467eba9e576820dfdd80"
          ]
        },
        "id": "5r8PnaBJSlxh",
        "outputId": "b4a77740-b4ae-43cf-f466-d46673ca71eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 32.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "GPU found ( Tesla K80 )\n",
            "num device avail:  1\n",
            "essays | bert-base | 512 | 512_head | cls\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "750bbe8ea77449429e2e49c9b63f5892",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c8ae835d3b3439da47b6ab6e9bc3e63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b30d62adc659440f8e4b418d263110df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99c42d0c77644c24bc9a7d956d5ed768",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ddc7a7a76e8436cbca8b78a0329cccb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXT :  1    1275\n",
            "0    1192\n",
            "Name: EXT, dtype: int64\n",
            "NEU :  1    1234\n",
            "0    1233\n",
            "Name: NEU, dtype: int64\n",
            "AGR :  1    1309\n",
            "0    1158\n",
            "Name: AGR, dtype: int64\n",
            "CON :  1    1254\n",
            "0    1213\n",
            "Name: CON, dtype: int64\n",
            "OPN :  1    1271\n",
            "0    1196\n",
            "Name: OPN, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "787.5030401297122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded all input_ids and targets from the data file!\n",
            "\n",
            "gpu mem alloc:  0.45  GB\n",
            "starting to extract LM embeddings...\n",
            "extracting embeddings for essays dataset: DONE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Personality Prediction using BERT Features**"
      ],
      "metadata": {
        "id": "bgfGRaExqUm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "import time\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# add parent directory to the path as well, if running from the finetune folder\n",
        "parent_dir = os.path.dirname(os.getcwd())\n",
        "sys.path.insert(0, parent_dir)\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "import utils.gen_utils as utils\n",
        "\n",
        "\n",
        "def get_inputs(inp_dir, dataset, embed, embed_mode, mode, layer):\n",
        "    \"\"\"Read data from pkl file and prepare for training.\"\"\"\n",
        "    file = open(\n",
        "        inp_dir + dataset + \"-\" + embed + \"-\" + embed_mode + \"-\" + mode + \".pkl\", \"rb\"\n",
        "    )\n",
        "    data = pickle.load(file)\n",
        "    author_ids, data_x, data_y = list(zip(*data))\n",
        "    file.close()\n",
        "\n",
        "    # alphaW is responsible for which BERT layer embedding we will be using\n",
        "    if layer == \"all\":\n",
        "        alphaW = np.full([n_hl], 1 / n_hl)\n",
        "\n",
        "    else:\n",
        "        alphaW = np.zeros([n_hl])\n",
        "        alphaW[int(layer) - 1] = 1\n",
        "\n",
        "    # just changing the way data is stored (tuples of minibatches) and\n",
        "    # getting the output for the required layer of BERT using alphaW\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    n_batches = len(data_y)\n",
        "    for ii in range(n_batches):\n",
        "        inputs.extend(np.einsum(\"k,kij->ij\", alphaW, data_x[ii]))\n",
        "        targets.extend(data_y[ii])\n",
        "\n",
        "    inputs = np.array(inputs)\n",
        "    full_targets = np.array(targets)\n",
        "\n",
        "    return inputs, full_targets\n",
        "\n",
        "\n",
        "def training(dataset, inputs, full_targets):\n",
        "    \"\"\"Train MLP model for each trait on 10-fold corss-validtion.\"\"\"\n",
        "    if dataset == \"kaggle\":\n",
        "        trait_labels = [\"E\", \"N\", \"F\", \"J\"]\n",
        "    else:\n",
        "        trait_labels = [\"EXT\", \"NEU\", \"AGR\", \"CON\", \"OPN\"]\n",
        "\n",
        "    n_splits = 10\n",
        "    fold_acc = {}\n",
        "    expdata = {}\n",
        "    expdata[\"acc\"], expdata[\"trait\"], expdata[\"fold\"] = [], [], []\n",
        "\n",
        "    for trait_idx in range(full_targets.shape[1]):\n",
        "        # convert targets to one-hot encoding\n",
        "        targets = full_targets[:, trait_idx]\n",
        "        n_data = targets.shape[0]\n",
        "\n",
        "        expdata[\"trait\"].extend([trait_labels[trait_idx]] * n_splits)\n",
        "        expdata[\"fold\"].extend(np.arange(1, n_splits + 1))\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
        "        k = -1\n",
        "        for train_index, test_index in skf.split(inputs, targets):\n",
        "            x_train, x_test = inputs[train_index], inputs[test_index]\n",
        "            y_train, y_test = targets[train_index], targets[test_index]\n",
        "            # converting to one-hot embedding\n",
        "            y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "            y_test = tf.keras.utils.to_categorical(y_test, num_classes=n_classes)\n",
        "            model = tf.keras.models.Sequential()\n",
        "\n",
        "            # define the neural network architecture\n",
        "            model.add(\n",
        "                tf.keras.layers.Dense(50, input_dim=hidden_dim, activation=\"relu\")\n",
        "            )\n",
        "            model.add(tf.keras.layers.Dense(n_classes))\n",
        "\n",
        "            k += 1\n",
        "            model.compile(\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                metrics=[\"mse\", \"accuracy\"],\n",
        "            )\n",
        "\n",
        "            history = model.fit(\n",
        "                x_train,\n",
        "                y_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=(x_test, y_test),\n",
        "                verbose=0,\n",
        "            )\n",
        "\n",
        "            expdata[\"acc\"].append(100 * max(history.history[\"val_accuracy\"]))\n",
        "    print(expdata)\n",
        "    df = pd.DataFrame.from_dict(expdata)\n",
        "    preds=model.predict(x_test)\n",
        "    return df,preds,y_test\n",
        "\n",
        "\n",
        "def logging(df, log_expdata=True):\n",
        "    \"\"\"Save results and each models config and hyper parameters.\"\"\"\n",
        "    (\n",
        "        df[\"network\"],\n",
        "        df[\"dataset\"],\n",
        "        df[\"lr\"],\n",
        "        df[\"batch_size\"],\n",
        "        df[\"epochs\"],\n",
        "        df[\"model_input\"],\n",
        "        df[\"embed\"],\n",
        "        df[\"layer\"],\n",
        "        df[\"mode\"],\n",
        "        df[\"embed_mode\"],\n",
        "        df[\"jobid\"],\n",
        "    ) = (\n",
        "        network,\n",
        "        dataset,\n",
        "        lr,\n",
        "        batch_size,\n",
        "        epochs,\n",
        "        MODEL_INPUT,\n",
        "        embed,\n",
        "        layer,\n",
        "        mode,\n",
        "        embed_mode,\n",
        "        jobid,\n",
        "    )\n",
        "\n",
        "    pd.set_option(\"display.max_columns\", None)\n",
        "    print(df.head(5))\n",
        "\n",
        "    # save the results of our experiment\n",
        "    if log_expdata:\n",
        "        Path(path).mkdir(parents=True, exist_ok=True)\n",
        "        if not os.path.exists(path + \"expdata.csv\"):\n",
        "            df.to_csv(path + \"expdata.csv\", mode=\"a\", header=True)\n",
        "        else:\n",
        "            df.to_csv(path + \"expdata.csv\", mode=\"a\", header=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    (\n",
        "        inp_dir,\n",
        "        dataset,\n",
        "        lr,\n",
        "        batch_size,\n",
        "        epochs,\n",
        "        log_expdata,\n",
        "        embed,\n",
        "        layer,\n",
        "        mode,\n",
        "        embed_mode,\n",
        "        jobid,\n",
        "    ) = utils.parse_args()\n",
        "    # embed_mode {mean, cls}\n",
        "    # mode {512_head, 512_tail, 256_head_tail}\n",
        "\n",
        "    network = \"MLP\"\n",
        "    MODEL_INPUT = \"LM_features\"\n",
        "    print(\"{} : {} : {} : {} : {}\".format(dataset, embed, layer, mode, embed_mode))\n",
        "    n_classes = 2\n",
        "    seed = jobid\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    start = time.time()\n",
        "    path = \"explogs/\"\n",
        "\n",
        "    if re.search(r\"base\", embed):\n",
        "        n_hl = 12\n",
        "        hidden_dim = 768\n",
        "\n",
        "    elif re.search(r\"large\", embed):\n",
        "        n_hl = 24\n",
        "        hidden_dim = 1024\n",
        "\n",
        "    inputs, full_targets = get_inputs(inp_dir, dataset, embed, embed_mode, mode, layer)\n",
        "    df,preds,y_test = training(dataset, inputs, full_targets)\n",
        "    logging(df, log_expdata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AxuVdaUI0D5",
        "outputId": "82e8e549-fef2-49a9-ef66-4e1c9d1019d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "essays : bert-base : 11 : 512_head : cls\n",
            "{'acc': [58.70445370674133, 57.894736528396606, 57.894736528396606, 58.29959511756897, 56.27530217170715, 55.46558499336243, 55.06072640419006, 56.91056847572327, 58.94308686256409, 54.878050088882446, 56.27530217170715, 52.63158082962036, 55.87044358253479, 61.94332242012024, 61.13360524177551, 59.109312295913696, 61.13360524177551, 52.84552574157715, 54.47154641151428, 59.34959053993225, 53.44129800796509, 61.538463830947876, 59.51417088508606, 55.06072640419006, 61.13360524177551, 56.68016076087952, 58.29959511756897, 57.723575830459595, 61.38211488723755, 63.008129596710205, 52.226722240448, 58.70445370674133, 59.51417088508606, 61.538463830947876, 57.894736528396606, 62.75303363800049, 56.27530217170715, 60.16260385513306, 54.06504273414612, 58.13007950782776, 60.72874665260315, 64.7773265838623, 66.80161952972412, 66.39676094055176, 59.51417088508606, 64.37246799468994, 64.7773265838623, 64.63414430618286, 62.60162591934204, 61.78861856460571], 'trait': ['EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'EXT', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'NEU', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'AGR', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'CON', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN', 'OPN'], 'fold': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
            "         acc trait  fold network dataset      lr  batch_size  epochs  \\\n",
            "0  58.704454   EXT     1     MLP  essays  0.0005          32      10   \n",
            "1  57.894737   EXT     2     MLP  essays  0.0005          32      10   \n",
            "2  57.894737   EXT     3     MLP  essays  0.0005          32      10   \n",
            "3  58.299595   EXT     4     MLP  essays  0.0005          32      10   \n",
            "4  56.275302   EXT     5     MLP  essays  0.0005          32      10   \n",
            "\n",
            "   model_input      embed layer      mode embed_mode  jobid  \n",
            "0  LM_features  bert-base    11  512_head        cls      0  \n",
            "1  LM_features  bert-base    11  512_head        cls      0  \n",
            "2  LM_features  bert-base    11  512_head        cls      0  \n",
            "3  LM_features  bert-base    11  512_head        cls      0  \n",
            "4  LM_features  bert-base    11  512_head        cls      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual=[]\n",
        "y_pred=[]\n",
        "for i in range(len(preds)):\n",
        "  y_actual.append(np.argmax(y_test[i]))\n",
        "  y_pred.append(np.argmax(preds[i]))\n",
        "import matplotlib.pyplot as plt1\n",
        " \n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt1.cm.Greens):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    import itertools\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        " \n",
        " \n",
        "    plt1.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt1.title(title)\n",
        "    plt1.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt1.xticks(tick_marks, classes, rotation=45)\n",
        "    plt1.yticks(tick_marks, classes)\n",
        " \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt1.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        " \n",
        "    plt1.ylabel('True label')\n",
        "    plt1.xlabel('Predicted label')\n",
        "    plt1.cm\n",
        "    plt1.show()\n",
        "cnf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "np.set_printoptions(precision=2)\n",
        " \n",
        "# Plot non-normalized confusion matrix\n",
        "plt1.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['0', '1'],\n",
        "                      \n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "r-UjUpMYpcCd",
        "outputId": "ed060a77-5a96-4cfc-be02-69ef97cb6f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}